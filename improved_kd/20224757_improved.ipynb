{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9703f326",
   "metadata": {
    "id": "WTUYbQLlYUQ-",
    "papermill": {
     "duration": 0.005148,
     "end_time": "2023-11-30T12:42:39.898782",
     "exception": false,
     "start_time": "2023-11-30T12:42:39.893634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EE837B Advances in Convolutional Neural Networks (Fall 2023)\n",
    "## Programming Assignment\n",
    "Department of Electrical Engineering, KAIST\n",
    "\n",
    "- Course Instructor : Prof. Junmo Kim\n",
    "\n",
    "- Primary TA : Hyounguk Shon\n",
    "\n",
    "- For questions regarding this assignment, use the course Q&A board on KLMS.\n",
    "\n",
    "---\n",
    "\n",
    "In this programming assignment, you are asked to reproduce the [Knowledge Distillation (KD) algorithm](https://arxiv.org/abs/1503.02531) in PyTorch. Your python code should distill a pre-trained teacher model into a smaller student model using the CIFAR-100 dataset. Additionally, we have an optional challenge for bonus credits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8b7511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:39.909643Z",
     "iopub.status.busy": "2023-11-30T12:42:39.909290Z",
     "iopub.status.idle": "2023-11-30T12:42:53.058967Z",
     "shell.execute_reply": "2023-11-30T12:42:53.057606Z"
    },
    "papermill": {
     "duration": 13.157546,
     "end_time": "2023-11-30T12:42:53.061186",
     "exception": false,
     "start_time": "2023-11-30T12:42:39.903640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\r\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\r\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "Installing collected packages: gdown\r\n",
      "Successfully installed gdown-4.7.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0390f830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:53.074072Z",
     "iopub.status.busy": "2023-11-30T12:42:53.073644Z",
     "iopub.status.idle": "2023-11-30T12:42:57.079764Z",
     "shell.execute_reply": "2023-11-30T12:42:57.078724Z"
    },
    "id": "RxMR39kBUTnQ",
    "papermill": {
     "duration": 4.015369,
     "end_time": "2023-11-30T12:42:57.082183",
     "exception": false,
     "start_time": "2023-11-30T12:42:53.066814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import gdown\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa17986",
   "metadata": {
    "id": "GYfj23oOmOr6",
    "papermill": {
     "duration": 0.005067,
     "end_time": "2023-11-30T12:42:57.092999",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.087932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define ResNet architecture\n",
    "Do not change this code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1246600f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.105903Z",
     "iopub.status.busy": "2023-11-30T12:42:57.105395Z",
     "iopub.status.idle": "2023-11-30T12:42:57.131819Z",
     "shell.execute_reply": "2023-11-30T12:42:57.130953Z"
    },
    "id": "FQdqM8z8ZM6l",
    "papermill": {
     "duration": 0.035309,
     "end_time": "2023-11-30T12:42:57.133781",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.098472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "    )\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, is_last=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.is_last = is_last\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        preact = out\n",
    "        out = F.relu(out)\n",
    "        if self.is_last:\n",
    "            return out, preact\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, depth, num_filters, block_name=\"BasicBlock\", num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        assert (\n",
    "            depth - 2\n",
    "        ) % 6 == 0, \"When use basicblock, depth should be 6n+2, e.g. 20, 32, 44, 56, 110, 1202\"\n",
    "        n = (depth - 2) // 6\n",
    "        block = BasicBlock\n",
    "\n",
    "        self.inplanes = num_filters[0]\n",
    "        self.conv1 = nn.Conv2d(3, num_filters[0], kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters[0])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, num_filters[1], n)\n",
    "        self.layer2 = self._make_layer(block, num_filters[2], n, stride=2)\n",
    "        self.layer3 = self._make_layer(block, num_filters[3], n, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(num_filters[3] * block.expansion, num_classes)\n",
    "        self.stage_channels = num_filters\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.inplanes,\n",
    "                    planes * block.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = list([])\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample, is_last=(blocks == 1))\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, is_last=(i == blocks - 1)))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_feat_modules(self):\n",
    "        feat_m = nn.ModuleList([])\n",
    "        feat_m.append(self.conv1)\n",
    "        feat_m.append(self.bn1)\n",
    "        feat_m.append(self.relu)\n",
    "        feat_m.append(self.layer1)\n",
    "        feat_m.append(self.layer2)\n",
    "        feat_m.append(self.layer3)\n",
    "        return feat_m\n",
    "\n",
    "    def get_bn_before_relu(self):\n",
    "        bn1 = self.layer1[-1].bn2\n",
    "        bn2 = self.layer2[-1].bn2\n",
    "        bn3 = self.layer3[-1].bn2\n",
    "        return [bn1, bn2, bn3]\n",
    "\n",
    "    def get_stage_channels(self):\n",
    "        return self.stage_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)  # 32x32\n",
    "        f0 = x\n",
    "\n",
    "        x, f1_pre = self.layer1(x)  # 32x32\n",
    "        f1 = x\n",
    "        x, f2_pre = self.layer2(x)  # 16x16\n",
    "        f2 = x\n",
    "        x, f3_pre = self.layer3(x)  # 8x8\n",
    "        f3 = x\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        avg = x.reshape(x.size(0), -1)\n",
    "        out = self.fc(avg)\n",
    "\n",
    "        return out\n",
    "\n",
    "def resnet8x4(**kwargs):\n",
    "    return ResNet(8, [32, 64, 128, 256], \"basicblock\", **kwargs)\n",
    "\n",
    "def resnet32x4(**kwargs):\n",
    "    return ResNet(32, [32, 64, 128, 256], \"basicblock\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda6ea5",
   "metadata": {
    "papermill": {
     "duration": 0.004892,
     "end_time": "2023-11-30T12:42:57.143866",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.138974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Base Trainer Class\n",
    "Do not change this code block.\n",
    "\n",
    "The base trainer will automatically download and load pre-trained teacher weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a96972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.155275Z",
     "iopub.status.busy": "2023-11-30T12:42:57.154963Z",
     "iopub.status.idle": "2023-11-30T12:42:57.166977Z",
     "shell.execute_reply": "2023-11-30T12:42:57.166137Z"
    },
    "id": "h-ukFLINYURx",
    "papermill": {
     "duration": 0.020009,
     "end_time": "2023-11-30T12:42:57.168906",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.148897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseTrainer:\n",
    "    #pretrained_teacher_link = 'https://drive.google.com/uc?id=1Gh3Z8BZ62PGD7PQiFiwmU9vMwMpF5F46'    \n",
    "    pretrained_teacher_link = 'https://drive.google.com/uc?id=1li1w_V3-NxPDUC9uofxijDnTABkp9rhD'\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        self.teacher = resnet32x4(num_classes=100)\n",
    "        self.student = resnet8x4(num_classes=100)\n",
    "        gdown.download(self.pretrained_teacher_link, './resnet_32x4.pth', resume=True)\n",
    "        self.teacher.load_state_dict(torch.load(\"./resnet_32x4.pth\", map_location=\"cpu\")[\"model\"])\n",
    "\n",
    "        self.train_transform = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "                ])\n",
    "        self.test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "                ])\n",
    "\n",
    "        self.train_set = datasets.CIFAR100('./data/', download=True, train=True, transform=self.train_transform)\n",
    "        self.test_set = datasets.CIFAR100('./data/', download=False, train=False, transform=self.test_transform)\n",
    "        self.test_dataloader = DataLoader(self.test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "    def save_student_checkpoint(self, ckpt_path):\n",
    "        state_dict = self.student.state_dict()\n",
    "        torch.save(state_dict, ckpt_path)\n",
    "\n",
    "    def load_student_checkpoint(self, ckpt_path):\n",
    "        state_dict = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        self.student.load_state_dict(state_dict)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate_student(self):\n",
    "        self.student.cuda().eval()\n",
    "        n = 0\n",
    "        correct = 0\n",
    "        for image, target in self.test_dataloader:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            output = self.student(image)\n",
    "            n += image.size(0)\n",
    "            correct += output.max(-1).indices.eq(target).sum().item()\n",
    "        accuracy = 100 * correct / n\n",
    "        return accuracy\n",
    "\n",
    "    def train_student(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a9e52f",
   "metadata": {
    "id": "6_kBr92qYURi",
    "papermill": {
     "duration": 0.00483,
     "end_time": "2023-11-30T12:42:57.178795",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.173965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8234d",
   "metadata": {
    "id": "Whrm65g0OQ0V",
    "papermill": {
     "duration": 0.005124,
     "end_time": "2023-11-30T12:42:57.188911",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.183787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this section, you need to implement training of the student model.\n",
    "Specifically, you need to implement the followings:\n",
    "\n",
    "1. Knowledge Distillation algorithm\n",
    "2. Training pipeline\n",
    "\n",
    "You are free to edit below skeleton code. You are not allowed to edit the model architecture and data augmentation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd9bc11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.200600Z",
     "iopub.status.busy": "2023-11-30T12:42:57.199901Z",
     "iopub.status.idle": "2023-11-30T12:42:57.206704Z",
     "shell.execute_reply": "2023-11-30T12:42:57.205919Z"
    },
    "id": "Z5CJM2fOOQ0W",
    "outputId": "59a4ef5b-e95c-4a8a-d606-496a066d1cea",
    "papermill": {
     "duration": 0.014658,
     "end_time": "2023-11-30T12:42:57.208552",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.193894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class KDLoss(nn.Module):\n",
    "#     def __init__(self, T=4.0):\n",
    "#         super(KDLoss, self).__init__()\n",
    "#         self.temperature = T\n",
    "#     def forward(self, student_logits, teacher_logits):\n",
    "#         soft_student = nn.Softmax(dim=1)(student_logits / self.temperature)\n",
    "#         soft_teacher = nn.Softmax(dim=1)(teacher_logits / self.temperature)\n",
    "#         kd_loss_1 = nn.KLDivLoss(reduction=\"batchmean\")(torch.log(soft_student), soft_teacher) * (self.temperature)**2\n",
    "#         kd_loss_2 = nn.KLDivLoss(reduction=\"batchmean\")(torch.log(soft_student.T), soft_teacher.T) * (self.temperature)**2\n",
    "#         return kd_loss_1 + kd_loss_2\n",
    "        \n",
    "# class KDTrainer(BaseTrainer):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         ### YOU MAY EDIT BELOW ###\n",
    "#         self.train_dataloader = DataLoader(self.train_set, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "#         self.init_lr = 0.05\n",
    "#         self.max_epoch = 240\n",
    "#         self.optimizer = optim.SGD(self.student.parameters(), lr=self.init_lr, momentum=0.9, weight_decay=5e-4)\n",
    "#         #...\n",
    "#         self.temperature = 4.0  # in original paper, range from 1 - 20\n",
    "#         self.alpha = 0.9\n",
    "#         self.beta = 1.0\n",
    "#         self.lr_scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[150, 180, 210], gamma=0.1)\n",
    "#         self.cl_loss = nn.CrossEntropyLoss()\n",
    "#         self.kd_loss = KDLoss(T=self.temperature)\n",
    "        \n",
    "#     def train_student(self):\n",
    "#         #### IMPLEMENT TRAINING HERE ####\n",
    "#         self.teacher.cuda().eval()\n",
    "#         self.student.cuda().train()\n",
    "#         #print(self.student)\n",
    "#         self.train_loss_arr = []\n",
    "#         self.val_acc_arr = []\n",
    "#         for epoch in range(self.max_epoch):\n",
    "#             print(len(self.train_dataloader.dataset))\n",
    "#             #...\n",
    "#             running_loss = 0.0\n",
    "#             for batch_idx, (data, hard_targets) in enumerate(self.train_dataloader):\n",
    "#                 data, hard_targets = data.cuda(), hard_targets.cuda()\n",
    "#                 with torch.no_grad():\n",
    "#                   teacher_logits = self.teacher(data) \n",
    "                \n",
    "#                 student_logits = self.student(data)\n",
    "#                 loss = self.alpha * self.cl_loss(nn.Softmax(dim=1)(student_logits), hard_targets) + self.beta * self.kd_loss(student_logits, teacher_logits)\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 self.optimizer.step()\n",
    "#                 running_loss += loss.item() # mean batch loss (1) + mean batch loss (2) + ....\n",
    "                \n",
    "#             train_loss = running_loss / len(self.train_dataloader) # divided by number of batch\n",
    "#             val_acc = self.evaluate_student()\n",
    "#             self.train_loss_arr.append(train_loss)\n",
    "#             self.val_acc_arr.append(val_acc)\n",
    "#             print(\"Epoch: %d, Loss: %f\" % (epoch+1, train_loss)) \n",
    "#             print(\"val_acc: \", val_acc)\n",
    "#             self.lr_scheduler.step()\n",
    "        \n",
    "#         # Save training history\n",
    "#         np.savetxt('train_loss_arr.csv', self.train_loss_arr, delimiter=',')\n",
    "#         np.savetxt('val_acc_arr.csv', self.val_acc_arr, delimiter=',')\n",
    "#         # Learning curve visualization\n",
    "#         self.train_loss_arr = np.loadtxt('train_loss_arr.csv', delimiter=',')\n",
    "#         epoch_arr = np.arange(1, self.max_epoch+1)\n",
    "#         plt.plot(epoch_arr, self.train_loss_arr)\n",
    "# #         plt.plot(epoch_arr, self.val_acc_arr)\n",
    "#         plt.xlabel(\"Epoch\")\n",
    "#         plt.ylabel(\"Training loss\")\n",
    "#         plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcef865",
   "metadata": {
    "id": "fMKPvEfFOQ0X",
    "papermill": {
     "duration": 0.005021,
     "end_time": "2023-11-30T12:42:57.218577",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.213556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training and Evaluation\n",
    "\n",
    "You do not need to modify the code in this section except the checkpoint path (**CKPT_PATH**).\n",
    "\n",
    "TAs will reproduce the results of your report with submitted checkpoint.\n",
    "\n",
    "**Before submission, make sure to check that the following code can print evaluation on your student model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f34a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.229904Z",
     "iopub.status.busy": "2023-11-30T12:42:57.229606Z",
     "iopub.status.idle": "2023-11-30T12:42:57.233430Z",
     "shell.execute_reply": "2023-11-30T12:42:57.232580Z"
    },
    "id": "c2ipeuStOQ0X",
    "outputId": "bbd36403-6a39-4668-a777-36594296bfb8",
    "papermill": {
     "duration": 0.011801,
     "end_time": "2023-11-30T12:42:57.235430",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.223629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CKPT_PATH = \"./student_checkpoint.pth\"\n",
    "\n",
    "# trainer = KDTrainer()\n",
    "# trainer.train_student()\n",
    "# trainer.save_student_checkpoint(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7580e9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.247276Z",
     "iopub.status.busy": "2023-11-30T12:42:57.247001Z",
     "iopub.status.idle": "2023-11-30T12:42:57.250743Z",
     "shell.execute_reply": "2023-11-30T12:42:57.249896Z"
    },
    "papermill": {
     "duration": 0.011991,
     "end_time": "2023-11-30T12:42:57.252580",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.240589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.load_student_checkpoint(CKPT_PATH)\n",
    "# accuracy = trainer.evaluate_student()\n",
    "\n",
    "# print(f\"Student model test accuracy: {accuracy:.3f} %\")\n",
    "# print(f\"Is above threshold performance? {accuracy > 72.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff7a0aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.264490Z",
     "iopub.status.busy": "2023-11-30T12:42:57.264221Z",
     "iopub.status.idle": "2023-11-30T12:42:57.283606Z",
     "shell.execute_reply": "2023-11-30T12:42:57.282904Z"
    },
    "papermill": {
     "duration": 0.027779,
     "end_time": "2023-11-30T12:42:57.285619",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.257840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b, eps=1e-8):\n",
    "    return (a * b).sum(1) / (a.norm(dim=1) * b.norm(dim=1) + eps)\n",
    "\n",
    "\n",
    "def pearson_correlation(a, b, eps=1e-8):\n",
    "    return cosine_similarity(a - a.mean(1).unsqueeze(1),\n",
    "                             b - b.mean(1).unsqueeze(1), eps)\n",
    "\n",
    "\n",
    "def inter_class_relation(y_s, y_t):\n",
    "    return 1 - pearson_correlation(y_s, y_t).mean()\n",
    "\n",
    "\n",
    "def intra_class_relation(y_s, y_t):\n",
    "    return inter_class_relation(y_s.T, y_t.T)\n",
    "\n",
    "\n",
    "class NewLoss(nn.Module):\n",
    "    def __init__(self, beta=1.0, gamma=1.0, T=4.0):\n",
    "        super(NewLoss, self).__init__()\n",
    "        self._beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits):\n",
    "        y_s = (student_logits / self.T).softmax(dim=1)\n",
    "        y_t = (teacher_logits / self.T).softmax(dim=1)\n",
    "\n",
    "        inter_loss = self.T**2 * inter_class_relation(y_s, y_t)\n",
    "        intra_loss = self.T**2 * intra_class_relation(y_s, y_t)\n",
    "        kd_loss = self._beta * inter_loss + self.gamma * intra_loss\n",
    "        return kd_loss\n",
    "\n",
    "class ImprovedKDTrainer(BaseTrainer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ### YOU MAY EDIT BELOW ###\n",
    "        self.train_dataloader = DataLoader(self.train_set, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "        self.init_lr = 0.05\n",
    "        self.max_epoch = 240\n",
    "        self.optimizer = optim.SGD(self.student.parameters(), lr=self.init_lr, momentum=0.9, weight_decay=5e-4)\n",
    "        #...\n",
    "        self.temperature = 4  # in original paper, range from 1 - 20\n",
    "        self.alpha = 0.9\n",
    "        self.beta = 1.0 - self.alpha # weighted average\n",
    "        self.lr_scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[150, 180, 210], gamma=0.1)\n",
    "        #self.lr_scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95, last_epoch=-1)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.use_kldiv = False\n",
    "        # self.kd_loss = KDLoss(use_kldiv=self.use_kldiv, T=self.temperature).cuda()\n",
    "        self.kd_loss = NewLoss(beta=2, gamma=2).cuda()\n",
    "\n",
    "\n",
    "    def train_student(self):\n",
    "        # print(self.student.get_feat_modules())\n",
    "        #### IMPLEMENT TRAINING HERE ####\n",
    "        self.teacher.cuda().eval()\n",
    "        self.student.cuda().train()\n",
    "        self.train_loss_arr = []\n",
    "        self.val_acc_arr = []\n",
    "        for epoch in range(self.max_epoch):\n",
    "            print(len(self.train_dataloader.dataset))\n",
    "            #...\n",
    "            running_loss = 0.0\n",
    "            for batch_idx, (data, hard_targets) in enumerate(self.train_dataloader):\n",
    "                data, hard_targets = data.cuda(), hard_targets.cuda()\n",
    "                with torch.no_grad():\n",
    "                  soft_targets = self.teacher(data) # only logits returned, no feat returned\n",
    "                  # print(soft_targets.shape)\n",
    "                logits = self.student(data)\n",
    "                loss = 0.1 * self.criterion(nn.Softmax(dim=1)(logits), hard_targets) + 0.9 * self.kd_loss(logits, soft_targets)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item() # mean batch loss (1) + mean batch loss (2) + ....\n",
    "\n",
    "            train_loss = running_loss / len(self.train_dataloader) # divided by number of batch\n",
    "#             if (epoch == 81 or epoch == 121):\n",
    "                # val_acc = self.evaluate_student()\n",
    "                # print(\"val_acc: \", val_acc)\n",
    "            self.train_loss_arr.append(train_loss)\n",
    "            # self.val_acc_arr.append(val_acc)\n",
    "            print(\"Epoch: %d, Loss: %f\" % (epoch+1, train_loss))\n",
    "            self.lr_scheduler.step()\n",
    "\n",
    "        # Save training history\n",
    "        np.savetxt('train_loss_arr.csv', self.train_loss_arr, delimiter=',')\n",
    "        # np.savetxt('val_acc_arr.csv', self.val_acc_arr, delimiter=',')\n",
    "        # Learning curve visualization\n",
    "        self.train_loss_arr = np.loadtxt('train_loss_arr.csv', delimiter=',')\n",
    "        epoch_arr = np.arange(1, self.max_epoch+1)\n",
    "        plt.plot(epoch_arr, self.train_loss_arr)\n",
    "#         plt.plot(epoch_arr, self.val_acc_arr)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Training loss\")\n",
    "        plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e0dba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T12:42:57.297219Z",
     "iopub.status.busy": "2023-11-30T12:42:57.296964Z",
     "iopub.status.idle": "2023-11-30T14:45:05.332032Z",
     "shell.execute_reply": "2023-11-30T14:45:05.331006Z"
    },
    "papermill": {
     "duration": 7328.043255,
     "end_time": "2023-11-30T14:45:05.334049",
     "exception": false,
     "start_time": "2023-11-30T12:42:57.290794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1li1w_V3-NxPDUC9uofxijDnTABkp9rhD\n",
      "To: /kaggle/working/resnet_32x4.pth\n",
      "100%|██████████| 59.6M/59.6M [00:00<00:00, 206MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:04<00:00, 34086108.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data/\n",
      "50000\n",
      "Epoch: 1, Loss: 42.357118\n",
      "50000\n",
      "Epoch: 2, Loss: 33.558041\n",
      "50000\n",
      "Epoch: 3, Loss: 28.729025\n",
      "50000\n",
      "Epoch: 4, Loss: 26.010185\n",
      "50000\n",
      "Epoch: 5, Loss: 24.212911\n",
      "50000\n",
      "Epoch: 6, Loss: 22.816385\n",
      "50000\n",
      "Epoch: 7, Loss: 21.805165\n",
      "50000\n",
      "Epoch: 8, Loss: 21.116349\n",
      "50000\n",
      "Epoch: 9, Loss: 20.499477\n",
      "50000\n",
      "Epoch: 10, Loss: 20.003345\n",
      "50000\n",
      "Epoch: 11, Loss: 19.651983\n",
      "50000\n",
      "Epoch: 12, Loss: 19.255201\n",
      "50000\n",
      "Epoch: 13, Loss: 18.986353\n",
      "50000\n",
      "Epoch: 14, Loss: 18.740957\n",
      "50000\n",
      "Epoch: 15, Loss: 18.639622\n",
      "50000\n",
      "Epoch: 16, Loss: 18.436668\n",
      "50000\n",
      "Epoch: 17, Loss: 18.266736\n",
      "50000\n",
      "Epoch: 18, Loss: 18.121607\n",
      "50000\n",
      "Epoch: 19, Loss: 18.028073\n",
      "50000\n",
      "Epoch: 20, Loss: 17.968925\n",
      "50000\n",
      "Epoch: 21, Loss: 17.839187\n",
      "50000\n",
      "Epoch: 22, Loss: 17.808104\n",
      "50000\n",
      "Epoch: 23, Loss: 17.623830\n",
      "50000\n",
      "Epoch: 24, Loss: 17.630339\n",
      "50000\n",
      "Epoch: 25, Loss: 17.505767\n",
      "50000\n",
      "Epoch: 26, Loss: 17.395718\n",
      "50000\n",
      "Epoch: 27, Loss: 17.423925\n",
      "50000\n",
      "Epoch: 28, Loss: 17.318122\n",
      "50000\n",
      "Epoch: 29, Loss: 17.249645\n",
      "50000\n",
      "Epoch: 30, Loss: 17.259507\n",
      "50000\n",
      "Epoch: 31, Loss: 17.139544\n",
      "50000\n",
      "Epoch: 32, Loss: 17.091815\n",
      "50000\n",
      "Epoch: 33, Loss: 17.080745\n",
      "50000\n",
      "Epoch: 34, Loss: 17.033435\n",
      "50000\n",
      "Epoch: 35, Loss: 16.987242\n",
      "50000\n",
      "Epoch: 36, Loss: 17.045181\n",
      "50000\n",
      "Epoch: 37, Loss: 16.972189\n",
      "50000\n",
      "Epoch: 38, Loss: 16.863927\n",
      "50000\n",
      "Epoch: 39, Loss: 16.897521\n",
      "50000\n",
      "Epoch: 40, Loss: 16.836072\n",
      "50000\n",
      "Epoch: 41, Loss: 16.883327\n",
      "50000\n",
      "Epoch: 42, Loss: 16.796000\n",
      "50000\n",
      "Epoch: 43, Loss: 16.798349\n",
      "50000\n",
      "Epoch: 44, Loss: 16.750610\n",
      "50000\n",
      "Epoch: 45, Loss: 16.777281\n",
      "50000\n",
      "Epoch: 46, Loss: 16.698203\n",
      "50000\n",
      "Epoch: 47, Loss: 16.665790\n",
      "50000\n",
      "Epoch: 48, Loss: 16.642507\n",
      "50000\n",
      "Epoch: 49, Loss: 16.641790\n",
      "50000\n",
      "Epoch: 50, Loss: 16.680117\n",
      "50000\n",
      "Epoch: 51, Loss: 16.647268\n",
      "50000\n",
      "Epoch: 52, Loss: 16.631477\n",
      "50000\n",
      "Epoch: 53, Loss: 16.565015\n",
      "50000\n",
      "Epoch: 54, Loss: 16.546650\n",
      "50000\n",
      "Epoch: 55, Loss: 16.552704\n",
      "50000\n",
      "Epoch: 56, Loss: 16.549425\n",
      "50000\n",
      "Epoch: 57, Loss: 16.533975\n",
      "50000\n",
      "Epoch: 58, Loss: 16.561673\n",
      "50000\n",
      "Epoch: 59, Loss: 16.534329\n",
      "50000\n",
      "Epoch: 60, Loss: 16.420677\n",
      "50000\n",
      "Epoch: 61, Loss: 16.475774\n",
      "50000\n",
      "Epoch: 62, Loss: 16.476589\n",
      "50000\n",
      "Epoch: 63, Loss: 16.438691\n",
      "50000\n",
      "Epoch: 64, Loss: 16.532832\n",
      "50000\n",
      "Epoch: 65, Loss: 16.407089\n",
      "50000\n",
      "Epoch: 66, Loss: 16.360326\n",
      "50000\n",
      "Epoch: 67, Loss: 16.377929\n",
      "50000\n",
      "Epoch: 68, Loss: 16.422544\n",
      "50000\n",
      "Epoch: 69, Loss: 16.395863\n",
      "50000\n",
      "Epoch: 70, Loss: 16.394663\n",
      "50000\n",
      "Epoch: 71, Loss: 16.424175\n",
      "50000\n",
      "Epoch: 72, Loss: 16.397173\n",
      "50000\n",
      "Epoch: 73, Loss: 16.419843\n",
      "50000\n",
      "Epoch: 74, Loss: 16.371625\n",
      "50000\n",
      "Epoch: 75, Loss: 16.306819\n",
      "50000\n",
      "Epoch: 76, Loss: 16.304907\n",
      "50000\n",
      "Epoch: 77, Loss: 16.310200\n",
      "50000\n",
      "Epoch: 78, Loss: 16.364898\n",
      "50000\n",
      "Epoch: 79, Loss: 16.319088\n",
      "50000\n",
      "Epoch: 80, Loss: 16.323803\n",
      "50000\n",
      "Epoch: 81, Loss: 16.330796\n",
      "50000\n",
      "Epoch: 82, Loss: 16.301453\n",
      "50000\n",
      "Epoch: 83, Loss: 16.301738\n",
      "50000\n",
      "Epoch: 84, Loss: 16.282856\n",
      "50000\n",
      "Epoch: 85, Loss: 16.322258\n",
      "50000\n",
      "Epoch: 86, Loss: 16.249107\n",
      "50000\n",
      "Epoch: 87, Loss: 16.346575\n",
      "50000\n",
      "Epoch: 88, Loss: 16.275882\n",
      "50000\n",
      "Epoch: 89, Loss: 16.191392\n",
      "50000\n",
      "Epoch: 90, Loss: 16.209918\n",
      "50000\n",
      "Epoch: 91, Loss: 16.261307\n",
      "50000\n",
      "Epoch: 92, Loss: 16.228900\n",
      "50000\n",
      "Epoch: 93, Loss: 16.181887\n",
      "50000\n",
      "Epoch: 94, Loss: 16.240517\n",
      "50000\n",
      "Epoch: 95, Loss: 16.243886\n",
      "50000\n",
      "Epoch: 96, Loss: 16.198344\n",
      "50000\n",
      "Epoch: 97, Loss: 16.249791\n",
      "50000\n",
      "Epoch: 98, Loss: 16.213580\n",
      "50000\n",
      "Epoch: 99, Loss: 16.204279\n",
      "50000\n",
      "Epoch: 100, Loss: 16.167803\n",
      "50000\n",
      "Epoch: 101, Loss: 16.208184\n",
      "50000\n",
      "Epoch: 102, Loss: 16.204023\n",
      "50000\n",
      "Epoch: 103, Loss: 16.117157\n",
      "50000\n",
      "Epoch: 104, Loss: 16.254839\n",
      "50000\n",
      "Epoch: 105, Loss: 16.129231\n",
      "50000\n",
      "Epoch: 106, Loss: 16.105175\n",
      "50000\n",
      "Epoch: 107, Loss: 16.184456\n",
      "50000\n",
      "Epoch: 108, Loss: 16.202408\n",
      "50000\n",
      "Epoch: 109, Loss: 16.074595\n",
      "50000\n",
      "Epoch: 110, Loss: 16.182170\n",
      "50000\n",
      "Epoch: 111, Loss: 16.175682\n",
      "50000\n",
      "Epoch: 112, Loss: 16.097940\n",
      "50000\n",
      "Epoch: 113, Loss: 16.139147\n",
      "50000\n",
      "Epoch: 114, Loss: 16.166025\n",
      "50000\n",
      "Epoch: 115, Loss: 16.084419\n",
      "50000\n",
      "Epoch: 116, Loss: 16.035911\n",
      "50000\n",
      "Epoch: 117, Loss: 16.109530\n",
      "50000\n",
      "Epoch: 118, Loss: 16.021770\n",
      "50000\n",
      "Epoch: 119, Loss: 16.064676\n",
      "50000\n",
      "Epoch: 120, Loss: 16.036882\n",
      "50000\n",
      "Epoch: 121, Loss: 16.025541\n",
      "50000\n",
      "Epoch: 122, Loss: 16.115639\n",
      "50000\n",
      "Epoch: 123, Loss: 16.106336\n",
      "50000\n",
      "Epoch: 124, Loss: 16.086827\n",
      "50000\n",
      "Epoch: 125, Loss: 16.105574\n",
      "50000\n",
      "Epoch: 126, Loss: 16.053624\n",
      "50000\n",
      "Epoch: 127, Loss: 16.103470\n",
      "50000\n",
      "Epoch: 128, Loss: 16.083516\n",
      "50000\n",
      "Epoch: 129, Loss: 15.928407\n",
      "50000\n",
      "Epoch: 130, Loss: 16.046696\n",
      "50000\n",
      "Epoch: 131, Loss: 16.098719\n",
      "50000\n",
      "Epoch: 132, Loss: 16.020699\n",
      "50000\n",
      "Epoch: 133, Loss: 16.055173\n",
      "50000\n",
      "Epoch: 134, Loss: 16.044858\n",
      "50000\n",
      "Epoch: 135, Loss: 16.030766\n",
      "50000\n",
      "Epoch: 136, Loss: 16.045987\n",
      "50000\n",
      "Epoch: 137, Loss: 16.124677\n",
      "50000\n",
      "Epoch: 138, Loss: 15.945328\n",
      "50000\n",
      "Epoch: 139, Loss: 16.059021\n",
      "50000\n",
      "Epoch: 140, Loss: 15.971440\n",
      "50000\n",
      "Epoch: 141, Loss: 15.989020\n",
      "50000\n",
      "Epoch: 142, Loss: 16.064024\n",
      "50000\n",
      "Epoch: 143, Loss: 16.057854\n",
      "50000\n",
      "Epoch: 144, Loss: 15.998054\n",
      "50000\n",
      "Epoch: 145, Loss: 16.087322\n",
      "50000\n",
      "Epoch: 146, Loss: 16.014959\n",
      "50000\n",
      "Epoch: 147, Loss: 16.094108\n",
      "50000\n",
      "Epoch: 148, Loss: 16.025205\n",
      "50000\n",
      "Epoch: 149, Loss: 15.968498\n",
      "50000\n",
      "Epoch: 150, Loss: 16.017758\n",
      "50000\n",
      "Epoch: 151, Loss: 12.508139\n",
      "50000\n",
      "Epoch: 152, Loss: 11.547388\n",
      "50000\n",
      "Epoch: 153, Loss: 11.119441\n",
      "50000\n",
      "Epoch: 154, Loss: 10.861073\n",
      "50000\n",
      "Epoch: 155, Loss: 10.688417\n",
      "50000\n",
      "Epoch: 156, Loss: 10.539843\n",
      "50000\n",
      "Epoch: 157, Loss: 10.348293\n",
      "50000\n",
      "Epoch: 158, Loss: 10.195422\n",
      "50000\n",
      "Epoch: 159, Loss: 10.093791\n",
      "50000\n",
      "Epoch: 160, Loss: 10.030258\n",
      "50000\n",
      "Epoch: 161, Loss: 9.897614\n",
      "50000\n",
      "Epoch: 162, Loss: 9.845476\n",
      "50000\n",
      "Epoch: 163, Loss: 9.744406\n",
      "50000\n",
      "Epoch: 164, Loss: 9.750159\n",
      "50000\n",
      "Epoch: 165, Loss: 9.664482\n",
      "50000\n",
      "Epoch: 166, Loss: 9.597326\n",
      "50000\n",
      "Epoch: 167, Loss: 9.576706\n",
      "50000\n",
      "Epoch: 168, Loss: 9.519048\n",
      "50000\n",
      "Epoch: 169, Loss: 9.466851\n",
      "50000\n",
      "Epoch: 170, Loss: 9.421066\n",
      "50000\n",
      "Epoch: 171, Loss: 9.407998\n",
      "50000\n",
      "Epoch: 172, Loss: 9.330591\n",
      "50000\n",
      "Epoch: 173, Loss: 9.324144\n",
      "50000\n",
      "Epoch: 174, Loss: 9.321642\n",
      "50000\n",
      "Epoch: 175, Loss: 9.286695\n",
      "50000\n",
      "Epoch: 176, Loss: 9.254097\n",
      "50000\n",
      "Epoch: 177, Loss: 9.296871\n",
      "50000\n",
      "Epoch: 178, Loss: 9.211355\n",
      "50000\n",
      "Epoch: 179, Loss: 9.218720\n",
      "50000\n",
      "Epoch: 180, Loss: 9.220459\n",
      "50000\n",
      "Epoch: 181, Loss: 8.276983\n",
      "50000\n",
      "Epoch: 182, Loss: 8.062301\n",
      "50000\n",
      "Epoch: 183, Loss: 7.916808\n",
      "50000\n",
      "Epoch: 184, Loss: 7.869004\n",
      "50000\n",
      "Epoch: 185, Loss: 7.842455\n",
      "50000\n",
      "Epoch: 186, Loss: 7.808972\n",
      "50000\n",
      "Epoch: 187, Loss: 7.811214\n",
      "50000\n",
      "Epoch: 188, Loss: 7.762063\n",
      "50000\n",
      "Epoch: 189, Loss: 7.730556\n",
      "50000\n",
      "Epoch: 190, Loss: 7.709008\n",
      "50000\n",
      "Epoch: 191, Loss: 7.707276\n",
      "50000\n",
      "Epoch: 192, Loss: 7.689920\n",
      "50000\n",
      "Epoch: 193, Loss: 7.657885\n",
      "50000\n",
      "Epoch: 194, Loss: 7.652784\n",
      "50000\n",
      "Epoch: 195, Loss: 7.611781\n",
      "50000\n",
      "Epoch: 196, Loss: 7.608282\n",
      "50000\n",
      "Epoch: 197, Loss: 7.576087\n",
      "50000\n",
      "Epoch: 198, Loss: 7.577187\n",
      "50000\n",
      "Epoch: 199, Loss: 7.566422\n",
      "50000\n",
      "Epoch: 200, Loss: 7.557350\n",
      "50000\n",
      "Epoch: 201, Loss: 7.475997\n",
      "50000\n",
      "Epoch: 202, Loss: 7.513204\n",
      "50000\n",
      "Epoch: 203, Loss: 7.503208\n",
      "50000\n",
      "Epoch: 204, Loss: 7.507938\n",
      "50000\n",
      "Epoch: 205, Loss: 7.458021\n",
      "50000\n",
      "Epoch: 206, Loss: 7.465968\n",
      "50000\n",
      "Epoch: 207, Loss: 7.479519\n",
      "50000\n",
      "Epoch: 208, Loss: 7.437292\n",
      "50000\n",
      "Epoch: 209, Loss: 7.425518\n",
      "50000\n",
      "Epoch: 210, Loss: 7.420120\n",
      "50000\n",
      "Epoch: 211, Loss: 7.312599\n",
      "50000\n",
      "Epoch: 212, Loss: 7.292172\n",
      "50000\n",
      "Epoch: 213, Loss: 7.305131\n",
      "50000\n",
      "Epoch: 214, Loss: 7.269520\n",
      "50000\n",
      "Epoch: 215, Loss: 7.283854\n",
      "50000\n",
      "Epoch: 216, Loss: 7.316820\n",
      "50000\n",
      "Epoch: 217, Loss: 7.280655\n",
      "50000\n",
      "Epoch: 218, Loss: 7.272145\n",
      "50000\n",
      "Epoch: 219, Loss: 7.269520\n",
      "50000\n",
      "Epoch: 220, Loss: 7.256098\n",
      "50000\n",
      "Epoch: 221, Loss: 7.257526\n",
      "50000\n",
      "Epoch: 222, Loss: 7.256149\n",
      "50000\n",
      "Epoch: 223, Loss: 7.243445\n",
      "50000\n",
      "Epoch: 224, Loss: 7.241452\n",
      "50000\n",
      "Epoch: 225, Loss: 7.268049\n",
      "50000\n",
      "Epoch: 226, Loss: 7.246185\n",
      "50000\n",
      "Epoch: 227, Loss: 7.216328\n",
      "50000\n",
      "Epoch: 228, Loss: 7.221292\n",
      "50000\n",
      "Epoch: 229, Loss: 7.246919\n",
      "50000\n",
      "Epoch: 230, Loss: 7.257522\n",
      "50000\n",
      "Epoch: 231, Loss: 7.207949\n",
      "50000\n",
      "Epoch: 232, Loss: 7.254395\n",
      "50000\n",
      "Epoch: 233, Loss: 7.224824\n",
      "50000\n",
      "Epoch: 234, Loss: 7.226889\n",
      "50000\n",
      "Epoch: 235, Loss: 7.235184\n",
      "50000\n",
      "Epoch: 236, Loss: 7.226374\n",
      "50000\n",
      "Epoch: 237, Loss: 7.219795\n",
      "50000\n",
      "Epoch: 238, Loss: 7.226776\n",
      "50000\n",
      "Epoch: 239, Loss: 7.263125\n",
      "50000\n",
      "Epoch: 240, Loss: 7.219585\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CKPT_PATH = \"./student_improved_checkpoint.pth\"\n",
    "\n",
    "trainer = ImprovedKDTrainer()\n",
    "trainer.train_student()\n",
    "trainer.save_student_checkpoint(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c1eaea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T14:45:05.395461Z",
     "iopub.status.busy": "2023-11-30T14:45:05.394537Z",
     "iopub.status.idle": "2023-11-30T14:45:08.480159Z",
     "shell.execute_reply": "2023-11-30T14:45:08.479195Z"
    },
    "papermill": {
     "duration": 3.118552,
     "end_time": "2023-11-30T14:45:08.482487",
     "exception": false,
     "start_time": "2023-11-30T14:45:05.363935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved student model test accuracy: 76.100 %\n"
     ]
    }
   ],
   "source": [
    "trainer.load_student_checkpoint(CKPT_PATH)\n",
    "accuracy = trainer.evaluate_student()\n",
    "\n",
    "print(f\"Improved student model test accuracy: {accuracy:.3f} %\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7354.659556,
   "end_time": "2023-11-30T14:45:11.106796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-30T12:42:36.447240",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
